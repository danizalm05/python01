{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     Missing Data\n",
    "\n",
    "https://www.tutorialspoint.com/python_pandas/python_pandas_missing_data.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -0.917498 -0.756065  0.046795\n",
      "c -2.055468 -0.227046  0.047230\n",
      "e  2.841160  0.776425  1.386045\n",
      "f -1.401719  0.185826 -0.635055\n",
      "h -1.004385 -1.651094  0.293613 \n",
      "\n",
      "        one       two     three\n",
      "a -0.917498 -0.756065  0.046795\n",
      "b       NaN       NaN       NaN\n",
      "c -2.055468 -0.227046  0.047230\n",
      "d       NaN       NaN       NaN\n",
      "e  2.841160  0.776425  1.386045\n",
      "f -1.401719  0.185826 -0.635055\n",
      "g       NaN       NaN       NaN\n",
      "h -1.004385 -1.651094  0.293613\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f',\n",
    "'h'],columns=['one', 'two', 'three'])\n",
    "print(df,'\\n')\n",
    "# Using reindexing,  create  a DataFrame with missing values\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    False\n",
      "b     True\n",
      "c    False\n",
      "d     True\n",
      "e    False\n",
      "f    False\n",
      "g     True\n",
      "h    False\n",
      "Name: one, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print (df['one'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one      False\n",
      "two      False\n",
      "three     True\n",
      "Name: a, dtype: bool\n"
     ]
    }
   ],
   "source": [
    " print (df.loc['a']>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     True\n",
      "b    False\n",
      "c     True\n",
      "d    False\n",
      "e     True\n",
      "f     True\n",
      "g    False\n",
      "h     True\n",
      "Name: one, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print (df['one'].notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.5379108416548286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (df['one'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Series.sum of one     NaN\n",
      "two     NaN\n",
      "three   NaN\n",
      "Name: b, dtype: float64>\n"
     ]
    }
   ],
   "source": [
    " #   When summing data, NA will be treated as Zero\n",
    " #   If the data are all NA, then the result will be NA\n",
    "print (df.loc['b'].sum )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning / Filling Missing Data\n",
    "\n",
    "Pandas provides various methods for cleaning the missing values. \n",
    "\n",
    "The fillna function can “fill in” NA values with non-null data in a couple of ways. \n",
    "\n",
    "Fill NA Forward and Backward\n",
    "\n",
    "Using the concepts of filling discussed in the ReIndexing Chapter we will fill the missing values.\n",
    "\n",
    " \n",
    "1. \t pad/fill: Fill methods Forward\n",
    "2. \t bfill/backfill: Fill methods Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a  0.211518 -1.125271  1.124714\n",
      "c  0.198795  0.751502 -1.003588\n",
      "e -0.075590  0.646696  0.160152 \n",
      "\n",
      "        one       two     three\n",
      "a  0.211518 -1.125271  1.124714\n",
      "b       NaN       NaN       NaN\n",
      "c  0.198795  0.751502 -1.003588 \n",
      "\n",
      "NaN replaced with '0':\n",
      "        one       two     three\n",
      "a  0.211518 -1.125271  1.124714\n",
      "b  0.000000  0.000000  0.000000\n",
      "c  0.198795  0.751502 -1.003588\n"
     ]
    }
   ],
   "source": [
    " df = pd.DataFrame(np.random.randn(3, 3), index=['a', 'c', 'e'],columns=['one',\n",
    "'two', 'three'])\n",
    "print (df,'\\n')\n",
    "df = df.reindex(['a', 'b', 'c'])\n",
    "print (df,'\\n')\n",
    "print (\"NaN replaced with '0':\")\n",
    "print (df.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -0.836439  1.035451 -1.445191\n",
      "c -0.532154 -0.157440 -0.348806\n",
      "e  2.113150 -0.805061  1.633832\n",
      "f -0.054621 -0.132664 -0.766857\n",
      "h -1.927972 -1.100825  0.283997 \n",
      "\n",
      "        one       two     three\n",
      "a -0.836439  1.035451 -1.445191\n",
      "b       NaN       NaN       NaN\n",
      "c -0.532154 -0.157440 -0.348806\n",
      "d       NaN       NaN       NaN\n",
      "e  2.113150 -0.805061  1.633832\n",
      "f -0.054621 -0.132664 -0.766857\n",
      "g       NaN       NaN       NaN\n",
      "h -1.927972 -1.100825  0.283997 \n",
      "\n",
      "        one       two     three\n",
      "a -0.836439  1.035451 -1.445191\n",
      "b -0.836439  1.035451 -1.445191\n",
      "c -0.532154 -0.157440 -0.348806\n",
      "d -0.532154 -0.157440 -0.348806\n",
      "e  2.113150 -0.805061  1.633832\n",
      "f -0.054621 -0.132664 -0.766857\n",
      "g -0.054621 -0.132664 -0.766857\n",
      "h -1.927972 -1.100825  0.283997\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f',\n",
    "'h'],columns=['one', 'two', 'three'])\n",
    "print (df,'\\n')\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "print (df,'\\n')\n",
    "print (df.fillna(method='pad') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a  1.731050  0.294265 -1.675840\n",
      "c  0.146366 -0.003691  0.450147\n",
      "e -1.531766 -1.503317  0.714540\n",
      "f -0.638858  0.147345  0.295422\n",
      "h  1.180059 -0.062120  0.250216\n",
      "        one       two     three\n",
      "a  1.731050  0.294265 -1.675840\n",
      "b  0.146366 -0.003691  0.450147\n",
      "c  0.146366 -0.003691  0.450147\n",
      "d -1.531766 -1.503317  0.714540\n",
      "e -1.531766 -1.503317  0.714540\n",
      "f -0.638858  0.147345  0.295422\n",
      "g  1.180059 -0.062120  0.250216\n",
      "h  1.180059 -0.062120  0.250216\n"
     ]
    }
   ],
   "source": [
    " df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f',\n",
    "'h'],columns=['one', 'two', 'three'])\n",
    "print (df )\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "\n",
    "print (df.fillna(method='backfill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Missing Values\n",
    "\n",
    "If you want to simply exclude the missing values, then use the dropna function along with the axis argument. By default, axis=0, i.e., along row, which means that if any value within a row is NA then the whole row is excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -0.972392  1.002977 -0.606287\n",
      "c  0.458623  0.897217 -0.405844\n",
      "e -0.785076 -1.286895  1.208165\n",
      "f -1.502353  0.618487 -0.771985\n",
      "h -0.102073  1.056875  1.451390\n",
      "        one       two     three\n",
      "a -0.972392  1.002977 -0.606287\n",
      "b       NaN       NaN       NaN\n",
      "c  0.458623  0.897217 -0.405844\n",
      "d       NaN       NaN       NaN\n",
      "e -0.785076 -1.286895  1.208165\n",
      "f -1.502353  0.618487 -0.771985\n",
      "g       NaN       NaN       NaN\n",
      "h -0.102073  1.056875  1.451390\n",
      "        one       two     three\n",
      "a -0.972392  1.002977 -0.606287\n",
      "c  0.458623  0.897217 -0.405844\n",
      "e -0.785076 -1.286895  1.208165\n",
      "f -1.502353  0.618487 -0.771985\n",
      "h -0.102073  1.056875  1.451390\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f',\n",
    "'h'],columns=['one', 'two', 'three'])\n",
    "print(df)\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "print(df)\n",
    "print (df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three\n",
      "a -0.407357  1.069346  0.841569\n",
      "b       NaN       NaN       NaN\n",
      "c  0.791218 -0.930454 -0.247777\n",
      "d       NaN       NaN       NaN\n",
      "e -0.413518  0.509508 -0.015421\n",
      "f  0.227857 -0.262540 -0.604816\n",
      "g       NaN       NaN       NaN\n",
      "h -0.839743 -0.791146 -0.846235\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [a, b, c, d, e, f, g, h]\n"
     ]
    }
   ],
   "source": [
    " df = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f',\n",
    "'h'],columns=['one', 'two', 'three'])\n",
    "\n",
    "df = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n",
    "print(df)\n",
    "print (df.dropna(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    one   two\n",
      "0    10  1000\n",
      "1    20     0\n",
      "2    30    30\n",
      "3    40    40\n",
      "4    50    50\n",
      "5  2000    60\n",
      "   one  two\n",
      "0   10   10\n",
      "1   20    0\n",
      "2   30   30\n",
      "3   40   40\n",
      "4   50   50\n",
      "5   60   60\n"
     ]
    }
   ],
   "source": [
    "#replace a generic value with some specific value\n",
    "df = pd.DataFrame({'one':[10,20,30,40,50,2000], 'two':[1000,0,30,40,50,60]})\n",
    "print(df)\n",
    "print (df.replace({1000:10,2000:60}) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupBy\n",
    "https://www.tutorialspoint.com/python_pandas/python_pandas_groupby.htm\n",
    "\n",
    "Any groupby operation involves one of the following operations on the original object. \n",
    "\n",
    "   1  Splitting the Object\n",
    "\n",
    "   2  Applying a function\n",
    "\n",
    "   3  Combining the results\n",
    "\n",
    "In many situations, we split the data into sets and we apply some functionality on each subset.\n",
    "In the apply functionality, we can perform the following operations −\n",
    "\n",
    "    1 Aggregation − computing a summary statistic\n",
    "\n",
    "    2 Transformation − perform some group-specific operation\n",
    "\n",
    "    3 Filtration − discarding the data with some condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Team  Rank  Year  Points\n",
      "0   Riders     1  2014     876\n",
      "1   Riders     2  2015     789\n",
      "2   Devils     2  2014     863\n",
      "3   Devils     3  2015     673\n",
      "4    Kings     3  2014     741\n",
      "5    kings     4  2015     812\n",
      "6    Kings     1  2016     756\n",
      "7    Kings     1  2017     788\n",
      "8   Riders     2  2016     694\n",
      "9   Royals     4  2014     701\n",
      "10  Royals     1  2015     804\n",
      "11  Riders     2  2017     690\n"
     ]
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "print (df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000289F69A02B0> \n",
      "\n",
      "{'Devils': Int64Index([2, 3], dtype='int64'), 'Kings': Int64Index([4, 6, 7], dtype='int64'), 'Riders': Int64Index([0, 1, 8, 11], dtype='int64'), 'Royals': Int64Index([9, 10], dtype='int64'), 'kings': Int64Index([5], dtype='int64')} \n",
      "\n",
      "{('Devils', 2014): Int64Index([2], dtype='int64'), ('Devils', 2015): Int64Index([3], dtype='int64'), ('Kings', 2014): Int64Index([4], dtype='int64'), ('Kings', 2016): Int64Index([6], dtype='int64'), ('Kings', 2017): Int64Index([7], dtype='int64'), ('Riders', 2014): Int64Index([0], dtype='int64'), ('Riders', 2015): Int64Index([1], dtype='int64'), ('Riders', 2016): Int64Index([8], dtype='int64'), ('Riders', 2017): Int64Index([11], dtype='int64'), ('Royals', 2014): Int64Index([9], dtype='int64'), ('Royals', 2015): Int64Index([10], dtype='int64'), ('kings', 2015): Int64Index([5], dtype='int64')} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (df.groupby('Team'),'\\n')\n",
    "print (df.groupby('Team').groups,'\\n')\n",
    "print (df.groupby(['Team','Year']).groups,'\\n')#Group by with multiple columns\n",
    "#print (df.groupby(['Team','Year']).groups('Royals', 2014),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating through Groups\n",
    "\n",
    "With the groupby object in hand, we can iterate through the object similar to itertools.obj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000289F6A10438>\n",
      "[ 1 ]:   2014\n",
      "     Team  Rank  Year  Points\n",
      "0  Riders     1  2014     876\n",
      "2  Devils     2  2014     863\n",
      "4   Kings     3  2014     741\n",
      "9  Royals     4  2014     701  \n",
      "\n",
      "[ 2 ]:   2015\n",
      "      Team  Rank  Year  Points\n",
      "1   Riders     2  2015     789\n",
      "3   Devils     3  2015     673\n",
      "5    kings     4  2015     812\n",
      "10  Royals     1  2015     804  \n",
      "\n",
      "[ 3 ]:   2016\n",
      "     Team  Rank  Year  Points\n",
      "6   Kings     1  2016     756\n",
      "8  Riders     2  2016     694  \n",
      "\n",
      "[ 4 ]:   2017\n",
      "      Team  Rank  Year  Points\n",
      "7    Kings     1  2017     788\n",
      "11  Riders     2  2017     690  \n",
      "\n",
      " \n",
      " \n",
      " grouped.get_group(2017) \n",
      "----------------------\n",
      "       Team  Rank  Year  Points\n",
      "7    Kings     1  2017     788\n",
      "11  Riders     2  2017     690\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('Year')\n",
    "i=1;\n",
    "print(grouped)\n",
    "for n,g in grouped:\n",
    "  print('[',i,']:  ',n)\n",
    "  i=i+1\n",
    "  \n",
    "  print (g,' \\n')\n",
    "print (\" \\n \\n grouped.get_group(2017) \\n----------------------\\n\",grouped.get_group(2017))    #select a single group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Aggregations\n",
    "\n",
    "An aggregated function returns a single aggregated value for each group. \n",
    "\n",
    "Once the group by object is created, several aggregation operations can be performed on the grouped data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "2014    795.25\n",
      "2015    769.50\n",
      "2016    725.00\n",
      "2017    739.00\n",
      "Name: Points, dtype: float64\n",
      "      Team  Rank  Points\n",
      "Year                    \n",
      "2014     4     4       4\n",
      "2015     4     4       4\n",
      "2016     2     2       2\n",
      "2017     2     2       2\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('Year')\n",
    "print (grouped['Points'].agg(np.mean) )# mean of points for  the year\n",
    "print (grouped.agg(np.size)) #size of each group i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sum        mean         std\n",
      "Team                                \n",
      "Devils  1536  768.000000  134.350288\n",
      "Kings   2285  761.666667   24.006943\n",
      "Riders  3049  762.250000   88.567771\n",
      "Royals  1505  752.500000   72.831998\n",
      "kings    812  812.000000         NaN\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('Team')\n",
    "print (grouped['Points'].agg([np.sum, np.mean, np.std]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations\n",
    "\n",
    "Transformation on a group or a column returns an object that is indexed the same size of that is being grouped. Thus, the transform should return a result that is the same size as that of a group chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Rank       Year     Points\n",
      "0  -15.000000 -11.618950  12.843272\n",
      "1    5.000000  -3.872983   3.020286\n",
      "2   -7.071068  -7.071068   7.071068\n",
      "3    7.071068   7.071068  -7.071068\n",
      "4   11.547005 -10.910895  -8.608621\n",
      "5         NaN        NaN        NaN\n",
      "6   -5.773503   2.182179  -2.360428\n",
      "7   -5.773503   8.728716  10.969049\n",
      "8    5.000000   3.872983  -7.705963\n",
      "9    7.071068  -7.071068  -7.071068\n",
      "10  -7.071068   7.071068   7.071068\n",
      "11   5.000000  11.618950  -8.157595\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('Team')\n",
    "score = lambda x: (x - x.mean()) / x.std()*10\n",
    "print (grouped.transform(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtration\n",
    "\n",
    "Filtration filters the data on a defined criteria and returns the subset of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Team  Rank  Year  Points\n",
      "0   Riders     1  2014     876\n",
      "1   Riders     2  2015     789\n",
      "4    Kings     3  2014     741\n",
      "6    Kings     1  2016     756\n",
      "7    Kings     1  2017     788\n",
      "8   Riders     2  2016     694\n",
      "11  Riders     2  2017     690\n"
     ]
    }
   ],
   "source": [
    "#I  return the teams which have participated three or more times in IPL.\n",
    "\n",
    "print (df.groupby('Team').filter(lambda x: len(x) >= 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging/Joining\n",
    "\n",
    "https://www.tutorialspoint.com/python_pandas/python_pandas_merging_joining.htm\n",
    " \n",
    "<b>pd.merge( left, right,  how='inner',  on=None,  left_on=None,  right_on=None,\n",
    "left_index=False,  right_index=False,  sort=True)</b>\n",
    "\n",
    "<b>left −</b> A DataFrame object.\n",
    "\n",
    "<b>right −</b> Another DataFrame object.\n",
    "\n",
    "<b>on − </b>Columns (names) to join on. Must be found in both the left and right DataFrame objects.\n",
    "left_on −</b> Columns from the left DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n",
    "\n",
    "<b>right_on − </b>Columns from the right DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n",
    "\n",
    "<b>left_index − </b>If True, use the index (row labels) from the left DataFrame as its join key(s). In case of a DataFrame with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the right DataFrame.\n",
    "\n",
    "<b>right_index − </b>Same usage as left_index for the right DataFrame.\n",
    "\n",
    "<b>how −</b> One of 'left', 'right', 'outer', 'inner'. Defaults to inner. Each method has been described below.\n",
    "\n",
    "<b>sort − </b>Sort the result DataFrame by the join keys in lexicographical order. Defaults to True, setting to False will improve the performance substantially in many cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    Name subject_id\n",
      "0   1    Alex       sub1\n",
      "1   2     Amy       sub2\n",
      "2   3   Allen       sub4\n",
      "3   4   Alice       sub6\n",
      "4   5  Ayoung       sub5 \n",
      "\n",
      "\n",
      "    id   Name subject_id\n",
      "0   1  Billy       sub2\n",
      "1   2  Brian       sub4\n",
      "2   3   Bran       sub3\n",
      "3   4  Bryce       sub6\n",
      "4   5  Betty       sub5\n"
     ]
    }
   ],
   "source": [
    "left = pd.DataFrame({\n",
    "   'id':[1,2,3,4,5],\n",
    "   'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "   'subject_id':['sub1','sub2','sub4','sub6','sub5']})\n",
    "right = pd.DataFrame(\n",
    "   {'id':[1,2,3,4,5],\n",
    "   'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "   'subject_id':['sub2','sub4','sub3','sub6','sub5']})\n",
    "print (left,'\\n\\n\\n',  right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Name_x subject_id_x Name_y subject_id_y\n",
      "0   1    Alex         sub1  Billy         sub2\n",
      "1   2     Amy         sub2  Brian         sub4\n",
      "2   3   Allen         sub4   Bran         sub3\n",
      "3   4   Alice         sub6  Bryce         sub6\n",
      "4   5  Ayoung         sub5  Betty         sub5\n"
     ]
    }
   ],
   "source": [
    "#Merge Two DataFrames on a \n",
    "print (pd.merge(left,right,on='id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Name_x subject_id Name_y\n",
      "0   4   Alice       sub6  Bryce\n",
      "1   5  Ayoung       sub5  Betty\n"
     ]
    }
   ],
   "source": [
    "# Merge Two DataFrames on Multiple Keys\n",
    "print (pd.merge(left,right,on=['id','subject_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Using 'how' Argument\n",
    "\n",
    "The how argument to merge specifies how to determine which keys are to be included in the resulting table. If a key combination does not appear in either the left or the right tables, the values in the joined table will be NA.\n",
    "\n",
    "Here is a summary of the how options and their SQL equivalent names  \n",
    "\n",
    "<b>Merge Method \tSQL Equivalent \t      Description</b>\n",
    "\n",
    "   left \t        LEFT OUTER JOIN \tUse keys from left object\n",
    "   \n",
    "right       \tRIGHT OUTER JOIN \tUse keys from right object\n",
    "\n",
    "outer       \tFULL OUTER JOIN \tUse union of keys\n",
    "\n",
    "inner       \tINNER JOIN \tUse     intersection of keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
