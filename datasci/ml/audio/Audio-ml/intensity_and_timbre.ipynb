{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Signal Processing for Machine Learning\n",
    "\n",
    "thesoundofai.slack.com\n",
    "<h2>chp 3:Intensity, loudness, and timbre</h2> \n",
    "https://www.youtube.com/watch?v=Jkoysm1fHUw&list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&index=3\n",
    "\n",
    "\n",
    "<h2>chp 4:Understanding Audio Signals for Machine Learning </h2>\n",
    "\n",
    "https://www.youtube.com/watch?v=daB9naGBVv4&list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&index=4\n",
    "\n",
    "<h2>chp 5:Types of Audio Features for Machine Learning </h2>  \n",
    "\n",
    "https://www.youtube.com/watch?v=ZZ9u1vUtcIA&list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&index=5\n",
    "\n",
    "<h2>chp 6:How to Extract Audio Features</h2>  \n",
    "\n",
    "https://www.youtube.com/watch?v=8A-W1xk7qs8&list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&index=6\n",
    "\n",
    "\n",
    "<h2>chp 7:Understanding Time Domain Audio Features</h2>\n",
    "    \n",
    "https://www.youtube.com/watch?v=SRrQ_v-OOSg&list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0&index=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>Sound power</b>\n",
    "\n",
    "● Rate at which energy is transferred\n",
    "● Energy per unit of time emitted by a sound source in all directions\n",
    "● Measured in watt (W)\n",
    "\n",
    "<b>Sound intensity</b>\n",
    "\n",
    "● Sound power per unit area\n",
    "● Measured in W/m2\n",
    "\n",
    "<b>Intensity level</b>\n",
    "\n",
    "● Logarithmic scale\n",
    "● Measured in decibels (dB)\n",
    "● Ration between two intensity values\n",
    "● Use an intensity of reference (TOH)\n",
    "\n",
    "<b>Loudness</b>\n",
    "\n",
    "● Subjective perception of sound intensity\n",
    "● Depends on duration / frequency of a sound\n",
    "● Depends on age\n",
    "● Measured in phons\n",
    "\n",
    "<b>Complex sound</b>\n",
    "\n",
    "● Superposition of sinusoids\n",
    "● A partial is a sinusoid used to describe a sound\n",
    "● The lowest partial is called fundamental frequency\n",
    "\n",
    "<b>Analog to digital conversion</b>\n",
    "● Sampling\n",
    "● Quantization\n",
    "\n",
    "<b>Sampling rate</b>  Sr = 1/T\n",
    "\n",
    "<b>Nyquist frequency</b> fn = Sr/2\n",
    "\n",
    "<b>Dynamic range</b>  Difference between largest/smallest signal a system can record\n",
    "\n",
    "<b>Signal-to-quantization-noise ratio   -  SQNR</b>\n",
    "● Relationship between max signal strength and\n",
    "quantization error\n",
    "● Correlates with dynamic range\n",
    "\n",
    "\n",
    "<b>Signal domain</b>\n",
    " 1. Time domain:  Amplitude envelope, Root-mean square energy,\n",
    "   Zero crossing rate\n",
    " 2. Frequency domain: Band energy ratio, Spectral centroid, Spectral flux \n",
    " 3. Time-frequency representation:  Spectrogram, Mel-spectrogram, Constant-Q transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Audio Signal</H1> \n",
    "\n",
    "<b>Amplitude envelope  AE</b> \n",
    "● Max amplitude value of all samples in a frame\n",
    "● Gives rough idea of loudness\n",
    "● Sensitive to outliers\n",
    "● Onset detection, music genre classification\n",
    "AEt =   max s(k)  -  Amplitude envelope at frame t\n",
    " \n",
    "<b>Root-mean-square energy</b>   \n",
    "● RMS of all samples in a frame t\n",
    "\n",
    "  RMSt =[   (1/K) *  (SIGMA (s(k))^2)   ] ^0.5      SIGMA from k=t*K to  k= (t+1)*K - 1\n",
    "  \n",
    "    Amplitute of k th  sample:  s(k)\n",
    "    Energy of k th  sample:    (s(k))^2\n",
    "    Sum of energy of all samples in frame t:   SIGMA (s(k))^2)\n",
    "    \n",
    "● Indicator of loudness\n",
    "● Less sensitive to outliers than AE\n",
    "\n",
    "● Application :Audio segmentation, music genre classification \n",
    "\n",
    "<b> Zero crossing rate (ZCRt)</b>   14:00\n",
    "● Number of times a signal crosses the horizontal axis\n",
    "        \n",
    "    ZCRt = ( 0.5* SIGMA  | sgn(s(k))- sgn(s(k+1)) | )   SIGMA from k=t*K to  k=(t+1)*K - 1\n",
    "<b>Zero crossing rate applications </b>\n",
    "● Recognition of percussive vs pitched sounds\n",
    "● Monophonic pitch estimation\n",
    "● Voice/unvoiced decision for speech signals    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FOLDER = \"C:/Users/gilfm/Music/wav\"\n",
    "#BASE_FOLDER = \"C:/Users/gilfm/Documents/d/python/datasci/ml/audio/Audio-ml\"\n",
    "violin_sound_file = \"violin.wav\"#\"violin_c.wav\"\n",
    "piano_sound_file = \"piano-c5.wav\"\n",
    "tremolo_sound_file = \"bass_tremolo.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sounds\n",
    "violin_c4, _ = librosa.load(os.path.join(BASE_FOLDER, violin_sound_file))\n",
    "piano_c5, _ = librosa.load(os.path.join(BASE_FOLDER, piano_sound_file))\n",
    "b_tremolo, _ = librosa.load(os.path.join(BASE_FOLDER, tremolo_sound_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(signal, name):\n",
    "    \"\"\"Compute power spectrogram with Short-Time Fourier Transform and plot result.\"\"\"\n",
    "    spectrogram = librosa.amplitude_to_db(librosa.stft(signal))\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    librosa.display.specshow(spectrogram, y_axis=\"log\")\n",
    "    plt.colorbar(format=\"%+2.0f dB\")\n",
    "    plt.title(f\"Log-frequency power spectrogram for {name}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(os.path.join(BASE_FOLDER, violin_sound_file)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(violin_c4, \"c4 on violin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(os.path.join(BASE_FOLDER, piano_sound_file)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(piano_c5, \"c5 on piano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(os.path.join(BASE_FOLDER, tremolo_sound_file)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(b_tremolo, \"tremolo_sound_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.fft.fft(violin_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mag = np.absolute(X)\n",
    "f = np.linspace(0, _, len(X_mag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "plt.plot(f, X_mag) # magnitude spectrum\n",
    "plt.xlabel('Frequency (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(violin_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
